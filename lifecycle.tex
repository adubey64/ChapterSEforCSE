\label{sec:lifecycle} 
Scientific software is designed to model some phenomena in the
physical world. The phenomena may be at microscopic level, for example
protein folding, or at really large scales, for example galaxy cluster
mergers, or have a range of scales. We use the term physical to also include chemical and
biological systems since physical processes are underlying building
blocks for those systems too. Their physical characteristics are
translated into mathematical models that are said to describe the
essential features of the behaviour of the system being
studied. These equations are then discretized, and numerical algorithms
are used to solve them. In general there are many more degrees of
freedom in the development and lifecycle of scientific software
that are not encountered elsewhere. 

\subsection{Development Cycle}
\label{sec:dev-cycle}
For scientific simualtions, modeling begins with equations that describe the
general class of behavior to be studied, for example the Navier-Stokes
equations describe the flow of compressible and incompressible
fluids, and Van-der-vaal equations describe force interactions among
molecules in a material. There may be more than one set of equations
if there are behaviors that are not adequately captured by one set.
In translating the model from mathematical representation to
computational representation two processes go on simultaneously,
discretization and approximation. One can argue that discretization is
by definition an approximation because it is in effect sampling
continuous behavior where information is lost between sampling
intervals. This loss shows up as error terms in the discretized
equations. But error terms are not the only
approximations. Depending upon the level of understanding of specific
sub-phenomena, and available compute resources, scientists also 
use their judgement to make other approximations. Sometimes, to focus on a
particular behavior, a term in an equation may be simplified or may be even completely
dropped. At other times some physical details may be dropped
from the model because they are not understood well enough by the
scientists. 

The next stage in developing the code is finding the appropriate
numerical methods for each of the models. Sometimes good methods exists that
can be used '' as-is'', at others they may need to be customized, or new
methods may need to be developed. There may need to be validation of
the method's applicability to the model if the method is new or
significantly modified. Unless an implementation of the method is
readily available as a third party software (stand-alone or in a
library), it has to be implemented and verified. It is at this stage
that the development of a CSE code begins to resemble that of general
software. The numerical algorithms is specified, the semantics are
understood, and they need to be translated into executable
code. Figure \ref{Fig:dev-cycle} gives an example of the development
cycle of a multiphysics application modeled using partial differential
equations. 

\begin{figure}[!t]
\centering
\includegraphics[ width=4.0in]{CSE-design}
\vskip -0.25in
\caption{Development cycle of modeling with partial differential equations}
\label{Fig:dev-cycle}
\end{figure}



\subsection{Verification and Validation}
\label{sec:vandv}
There are many stages in the development cycle of scientific software 
where errors can be introduced. Classes of these errors are mostly
orthogonal to one another, a good verification and validation
methodology will reflect and exploit that. The terms verification and 
validation are used in ways where they don't always mean the same
thing. In one narrow definition of validation, it ensures that the
mathematical model correctly defines the physical phenomena, while
verification makes sure that the implementation of the model is
correct. In other words, model is validated against observations or
experiments from the physical world, whereas verification encompasses
all other forms of  testing.   Other definitions give broader scope to
validation. For example, validation can also apply to a numerical
method through exercises such as code-to-code comparisons, and its
order can be validated through convergence studies. Similarly the
implementation of a solver can be validated against an analytically
obtained solution for some model if the same solver can be
applied and the analytical solution is also known.  Though this is not
always possible.  Irrespective of  specific defintions, what is true is that
correctness must be assured at all the stages from model to
implementation.  

There are many degrees of freedom in the process of deriving a
model as discussed in the previous section, therefore, the validation of the
model must be carefully caliberated by scientific experts. Similarly,
verification of a numerical method requires applied math expertise
because the method needs verification of its stability, accuracy and
order of  convergence in addition to correctness. Numerical methods
have their own error analysis because of approximations. Many of
these methods are themselves objects of ongoing research, so their
implementation may need modifications from time to time. Whenever
that happens the entire gamut of verification and validation needs to
be applied again. This is an instance of particular challenges in the
CSE software where no amount of specification is enough to hand the
implementation over to the software engineers/developers. A close
collaboration is a must because the process has to be iterative with
scientific judgement applied at every iteration. 

One other unique verification challenge in CSE software is the
consequences of finite machine precision of floating point
numbers. Any change in compilers, optimization levels, and even order
of operations can cause numerical drift in the solutions. Especially
in applications that have a large range of scales it can be extremely
difficult to differentiate between a legitimate bug and a numerical
drift. Therefore relying upon bitwise reproducibity of the solution is
rarely a sufficient method for verifying the continued correctness of
an application behavior. Robust diagnostics (such as statistics or
conservation of physical quantities) need to be built into the
verification process. Knowing the error bars also helps. This issue is
discussed in greater detail in chapter \ref{chp:testing}.

\subsection{Maintenance and Extensions}
\label{sec:maintain}
A typical software project undergoes a design and development phase,
followed by production and maintenance phase. This clearly
defined lifecyle rarely applies to scientific codes. In most successful multiphysics
codes the infrastructure and solver API's are the only entities that
have a distinct development phase which does not spill over into the
remainder of the lifecycle.  The development of CSE software is
usually responding to an immediate scientific need, so the codes get
employed in production as soon as a minimal set of computational
modules necessary for even one scientific project are
built. Similarly, the development of computational modules almost
never stops all through the code lifecycle because new findings in science
and math almost continuously place new demands on them. The additions
are mostly incremental when they incorporate new findings into an
existing feature, they can also be substantial when new capabilities
are added. The need for new capabilities may arise from 
greater model fidelity, or from trying to simulate a more complex
model. Sometimes a code designed for one scientific field may have
enough in common with another field that capabilities may be added to
enable it for the new field.   

Whatever may be the cause, co-existence of development and
production/maintenance phases is a constant challenge to the code
teams. It becomes acute when the code needs to undergo major version
changes. The former can be managed with some repository
discipline in the team coupled with a solid testing regime. The latter
is a much bigger challenge where the plan has to concern itself with
questions such as how much backward compatibility is suitable, how
much code can go offline, and how to reconcile ongoing development in
code sections that are substantially different between versions.
FLASH's example in section \ref{sec:FLASHSoftwareProcess} describes
a couple of strategies that met the conflicting needs of developers and
production users in both scenarios. Both required co-operation and
buy-in from all the stakeholders to be successful. 

\subsection{Using CSE Software}
\input{using}
